{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.00000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>1.743817</td>\n",
       "      <td>2.22881</td>\n",
       "      <td>4.183199</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.679298</td>\n",
       "      <td>7.636513</td>\n",
       "      <td>8.28974</td>\n",
       "      <td>1.310436</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>923.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  568454.000000         568454.000000            568454.00000   \n",
       "mean   284227.500000              1.743817                 2.22881   \n",
       "std    164098.679298              7.636513                 8.28974   \n",
       "min         1.000000              0.000000                 0.00000   \n",
       "25%    142114.250000              0.000000                 0.00000   \n",
       "50%    284227.500000              0.000000                 1.00000   \n",
       "75%    426340.750000              2.000000                 2.00000   \n",
       "max    568454.000000            866.000000               923.00000   \n",
       "\n",
       "               Score          Time  \n",
       "count  568454.000000  5.684540e+05  \n",
       "mean        4.183199  1.296257e+09  \n",
       "std         1.310436  4.804331e+07  \n",
       "min         1.000000  9.393408e+08  \n",
       "25%         4.000000  1.271290e+09  \n",
       "50%         5.000000  1.311120e+09  \n",
       "75%         5.000000  1.332720e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Reviews.csv')\n",
    "df.describe(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['Score']!=3]\n",
    "def partition(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    return 1\n",
    "df['Score']=df['Score'].map(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328732, 4)\n"
     ]
    }
   ],
   "source": [
    "df=df.sort_values(['UserId', 'Time'], ascending=True)\n",
    "df.drop_duplicates(subset=['UserId','Time'], keep='first', inplace=True)\n",
    "df.drop(['ProductId','UserId','ProfileName','Time','HelpfulnessNumerator','HelpfulnessDenominator'],axis=1,inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SumTex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136322</th>\n",
       "      <td>136323</td>\n",
       "      <td>1</td>\n",
       "      <td>Great for the Price</td>\n",
       "      <td>I have to say I was a little apprehensive to b...</td>\n",
       "      <td>Great for the Price . I have to say I was a li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516061</th>\n",
       "      <td>516062</td>\n",
       "      <td>1</td>\n",
       "      <td>AWESOME Coffee!!!!</td>\n",
       "      <td>Received my free K cups as a sample promotion ...</td>\n",
       "      <td>AWESOME Coffee!!!! . Received my free K cups a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516078</th>\n",
       "      <td>516079</td>\n",
       "      <td>1</td>\n",
       "      <td>Brooklyn Bean Roastery Breakfast Blend K-Cups</td>\n",
       "      <td>Brooklyn Bean Roastery Blend K-Cups are great ...</td>\n",
       "      <td>Brooklyn Bean Roastery Breakfast Blend K-Cups ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136544</th>\n",
       "      <td>136545</td>\n",
       "      <td>0</td>\n",
       "      <td>Less than satisfactory.  I gave the Brooklyn K...</td>\n",
       "      <td>Brooklyn \"French Roast\" K-Cup Coffee is not on...</td>\n",
       "      <td>Less than satisfactory.  I gave the Brooklyn K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83317</th>\n",
       "      <td>83318</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Green\" K-cup packaging sacrifices flavor</td>\n",
       "      <td>Overall its just OK when considering the price...</td>\n",
       "      <td>\"Green\" K-cup packaging sacrifices flavor . Ov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Score                                            Summary  \\\n",
       "136322  136323      1                                Great for the Price   \n",
       "516061  516062      1                                 AWESOME Coffee!!!!   \n",
       "516078  516079      1      Brooklyn Bean Roastery Breakfast Blend K-Cups   \n",
       "136544  136545      0  Less than satisfactory.  I gave the Brooklyn K...   \n",
       "83317    83318      0          \"Green\" K-cup packaging sacrifices flavor   \n",
       "\n",
       "                                                     Text  \\\n",
       "136322  I have to say I was a little apprehensive to b...   \n",
       "516061  Received my free K cups as a sample promotion ...   \n",
       "516078  Brooklyn Bean Roastery Blend K-Cups are great ...   \n",
       "136544  Brooklyn \"French Roast\" K-Cup Coffee is not on...   \n",
       "83317   Overall its just OK when considering the price...   \n",
       "\n",
       "                                                   SumTex  \n",
       "136322  Great for the Price . I have to say I was a li...  \n",
       "516061  AWESOME Coffee!!!! . Received my free K cups a...  \n",
       "516078  Brooklyn Bean Roastery Breakfast Blend K-Cups ...  \n",
       "136544  Less than satisfactory.  I gave the Brooklyn K...  \n",
       "83317   \"Green\" K-cup packaging sacrifices flavor . Ov...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SumTex']=df['Summary']+' . '+df['Text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing remove- NaN, punctuation marks ,html tags,words with length less than 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_html=re.compile('<.*?>')\n",
    "def clean_html(text):\n",
    "    return re.sub(sub_html,' ',text)\n",
    "sub_punc=re.compile('[~`@#$%^&*()_!+{}|:\"<>?/.,;=\\-\\[\\]\\'\\،،\"\\\\\\؟،]')\n",
    "def clean_punc(text):\n",
    "    return re.sub(sub_punc,'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SumTex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33958</th>\n",
       "      <td>33959</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I only used two maybe three tea bags and got p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Score Summary  \\\n",
       "33958  33959      0     NaN   \n",
       "\n",
       "                                                    Text SumTex  \n",
       "33958  I only used two maybe three tea bags and got p...    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(index=33958,inplace =True)\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down', 'and', 'until', 'its', 'off', 'wouldn', 'himself', 'under', 'why', 'will', 'she', 't', 'other', 'about', 'yourselves', 'are', \"mightn't\", 'hers', 'over', \"haven't\", 'just', 'is', 'your', 'theirs', 's', \"you'll\", 'haven', 'where', 'between', 'the', 'them', 'as', 'who', 'after', 'both', 'should', \"she's\", 'can', 'does', 'this', 'ma', 'than', 'it', 'any', 'what', 'been', 'has', \"shouldn't\", \"should've\", 'into', 'itself', \"won't\", \"weren't\", 'in', \"you're\", 'herself', 're', 'weren', 'isn', \"hadn't\", 'themselves', 'while', 'there', 'again', 'same', 'which', 'when', \"didn't\", 'a', 'some', 'below', 'hadn', \"needn't\", 'won', \"wouldn't\", 'most', 'by', \"don't\", 'her', 'an', 'now', 'i', 'their', 'm', 'doing', 've', 'not', 'shan', 'was', 'him', 'up', 'so', 'having', 'you', 'd', 'further', 'yourself', 'aren', 'doesn', 'too', \"shan't\", 'have', \"mustn't\", 'above', 'ain', 'my', 'didn', 'had', 'nor', \"that'll\", 'for', 'to', \"it's\", 'they', 'those', 'were', 'each', 'don', 'during', 'ourselves', 'whom', \"couldn't\", \"you'd\", 'out', 'more', 'yours', 'if', 'me', 'our', 'being', 'do', 'myself', 'against', 'of', 'how', 'y', 'no', 'only', 'll', 'on', 'few', \"you've\", 'these', 'or', 'here', 'that', 'am', 'mightn', \"hasn't\", 'o', 'but', 'such', 'his', 'we', 'hasn', \"wasn't\", \"isn't\", 'very', 'before', 'shouldn', \"aren't\", 'mustn', 'all', 'ours', 'did', 'be', 'because', 'he', \"doesn't\", 'couldn', 'own', 'through', 'wasn', 'needn', 'once', 'then', 'from', 'at', 'with'}\n"
     ]
    }
   ],
   "source": [
    "print(set(stopwords.words('english')))\n",
    "#some important stop words that should not be excluded, mostly negative words\n",
    "ss={ 'isn', 'mightn', 'no', 'needn', 'doesn', 'not', 'don', 'haven', 'ain', 'didn', 'won', 'weren'}\n",
    "stop = set(stopwords.words('english')).difference(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13374940 \n",
      " 17944167 \n",
      " 663.6518995761871\n"
     ]
    }
   ],
   "source": [
    "sno = SnowballStemmer(\"english\")\n",
    "summary=[]\n",
    "hit=miss=0\n",
    "start=time.time()\n",
    "for text in df['SumTex'].tolist():\n",
    "#         print('TExt',type(text))\n",
    "    text=text.lower()\n",
    "    text=clean_html(text)\n",
    "    text=word_tokenize(text)\n",
    "#         print('TExt',type(text))\n",
    "#         print('TExt',text)\n",
    "#         text=' '\n",
    "    string=[]\n",
    "    for word in text:\n",
    "#         print(word)\n",
    "#         print('word',type(word))\n",
    "        if any ([ word in stop,len(word)<3,not(word.isalpha())]):\n",
    "            miss+=1\n",
    "#             print(word)\n",
    "            continue\n",
    "        hit+=1\n",
    "#         print(word)\n",
    "        string.append(sno.stem(word))\n",
    "#         print(string)\n",
    "#         print('string',type(string))\n",
    "    summary.append(string)\n",
    "#     print(summary)\n",
    "#     print('summary',type(summary))\n",
    "print(hit,'\\n',miss,'\\n',(time.time()-start) )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_text']=summary\n",
    "df.drop(['Summary','Text','Id'],axis=1,inplace=True)\n",
    "df.to_csv('fine_food_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>SumTex</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the Price . I have to say I was a li...</td>\n",
       "      <td>['great', 'price', 'say', 'littl', 'apprehens'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AWESOME Coffee!!!! . Received my free K cups a...</td>\n",
       "      <td>['awesom', 'coffe', 'receiv', 'free', 'cup', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brooklyn Bean Roastery Breakfast Blend K-Cups ...</td>\n",
       "      <td>['brooklyn', 'bean', 'roasteri', 'breakfast', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Less than satisfactory.  I gave the Brooklyn K...</td>\n",
       "      <td>['less', 'satisfactori', 'gave', 'brooklyn', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Green\" K-cup packaging sacrifices flavor . Ov...</td>\n",
       "      <td>['green', 'packag', 'sacrific', 'flavor', 'ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                             SumTex  \\\n",
       "0      1  Great for the Price . I have to say I was a li...   \n",
       "1      1  AWESOME Coffee!!!! . Received my free K cups a...   \n",
       "2      1  Brooklyn Bean Roastery Breakfast Blend K-Cups ...   \n",
       "3      0  Less than satisfactory.  I gave the Brooklyn K...   \n",
       "4      0  \"Green\" K-cup packaging sacrifices flavor . Ov...   \n",
       "\n",
       "                                        Cleaned_text  \n",
       "0  ['great', 'price', 'say', 'littl', 'apprehens'...  \n",
       "1  ['awesom', 'coffe', 'receiv', 'free', 'cup', '...  \n",
       "2  ['brooklyn', 'bean', 'roasteri', 'breakfast', ...  \n",
       "3  ['less', 'satisfactori', 'gave', 'brooklyn', '...  \n",
       "4  ['green', 'packag', 'sacrific', 'flavor', 'ove...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('fine_food_data.csv')\n",
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(df['Cleaned_text'][0])\n",
    "def tostr(x):\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2) ) #in scikit-learn\n",
    "final_bigram_counts = count_vect.fit_transform(df['Cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328731, 2824988)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf= vectorizer.fit_transform(df['Cleaned_text'])\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_bigram_counts,df['Score'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9152356761525241"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8390040610217957"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tf,df['Score'], test_size=0.20, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss is: 0.19449908825330123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "clf = SGDClassifier( penalty='l1', loss='hinge', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print( \"The log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
